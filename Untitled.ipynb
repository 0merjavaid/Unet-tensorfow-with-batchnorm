{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'with tf.Session() as sess:\\n    # you need to initialize all variables\\n    tf.initialize_all_variables().run()\\n\\n\\n    print sess.run(a.up1,feed_dict={x:np.array([1,572,572,3])})'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class UNET:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def model(self,image):\n",
    "         \n",
    "        self.conv1_1=self.conv(image,3,3,64,\"conv1_1\")\n",
    "        self.conv1_2=self.conv(self.conv1_1,64,3,64,\"conv1_2\")\n",
    "        self.pool1=self.max_pool(self.conv1_2,\"pool1\")\n",
    "        \n",
    "        self.conv2_1=self.conv(self.pool1,64,3,128,\"conv2_1\")\n",
    "        self.conv2_2=self.conv(self.conv2_1,128,3,128,\"conv2_2\")\n",
    "        self.pool2=self.max_pool(self.conv2_2,\"pool2\")\n",
    "        \n",
    "        self.conv3_1=self.conv(self.pool2,128,3,256,\"conv3_1\")\n",
    "        self.conv3_2=self.conv(self.conv3_1,256,3,256,\"conv3_2\")\n",
    "        self.pool3=self.max_pool(self.conv3_2,\"pool3\")\n",
    "        \n",
    "        self.conv4_1=self.conv(self.pool3,256,3,512,\"conv4_1\")\n",
    "        self.conv4_2=self.conv(self.conv4_1,512,3,512,\"conv4_2\")\n",
    "        self.pool4=self.max_pool(self.conv4_2,\"pool4\")\n",
    "        \n",
    "        self.conv5_1=self.conv(self.pool4,512,3,1024,\"conv5_1\")\n",
    "        self.conv5_2=self.conv(self.conv5_1,1024,3,1024,\"conv5_2\") \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.up1=self.up_conv(self.conv5_2,\"up_conv_1\")\n",
    "        self.up1=self.crop_and_concat(self.conv4_2,self.up1)\n",
    "        self.conv6_1=self.conv(self.up1,1024,3,512,\"conv6_1\")\n",
    "        self.conv6_2=self.conv(self.conv6_1,512,3,512,\"conv6_2\")\n",
    "        \n",
    "        self.up2=self.up_conv(self.conv6_2,\"up_conv_2\")\n",
    "        self.up2=self.crop_and_concat(self.conv3_2,self.up2)  \n",
    "        self.conv7_1=self.conv(self.up2,512,3,256,\"conv7_1\")\n",
    "        self.conv7_2=self.conv(self.conv7_1,256,3,256,\"conv7_2\")\n",
    "        \n",
    "        self.up3=self.up_conv(self.conv7_2,\"up_conv_3\")\n",
    "        self.up3=self.crop_and_concat(self.conv2_2,self.up3)\n",
    "        self.conv8_1=self.conv(self.up3,256,3,128,\"conv8_1\")\n",
    "        self.conv8_2=self.conv(self.conv8_1,128,3,128,\"conv8_2\")\n",
    "        \n",
    "        self.up4=self.up_conv(self.conv8_2,\"up_conv_4\")\n",
    "        self.up4=self.crop_and_concat(self.conv1_2,self.up4)\n",
    "        self.conv9_1=self.conv(self.up4,128,3,64,\"conv9_1\")\n",
    "        self.conv9_2=self.conv(self.conv9_1,64,3,64,\"conv9_2\")\n",
    "        self.out=self.conv(self.conv9_2,64,1,2,\"out\")\n",
    "         \n",
    "        print \"Model created\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def max_pool(self,input,name):\n",
    "        return tf.nn.max_pool(value=input,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"VALID\",name=name)\n",
    "    \n",
    "    def conv(self,input,num_input_channel,filter_size,num_filter,name,use_relu=True):\n",
    "        weight_shape=[filter_size,filter_size,num_input_channel,num_filter]\n",
    "        weights=self.weight(weight_shape,name)\n",
    "        biases=self.bias(num_filter,name)\n",
    "        layer=tf.nn.conv2d(input=input,filter=weights,strides=[1,1,1,1],padding=\"VALID\")\n",
    "        final = tf.nn.bias_add(layer,biases)\n",
    "        if(use_relu):\n",
    "            final = tf.nn.relu(final)\n",
    "            \n",
    "        return final\n",
    "        \n",
    "    def up_conv(self,input,name):\n",
    "        stride=[1,2,2,1]\n",
    "        shape=input.get_shape().as_list()\n",
    "        weight_shape=[2,2,shape[3]/2 , shape[3]]\n",
    "        weights=self.weight(weight_shape,name)\n",
    "        out_shape=[-1,shape[1]*2,shape[2]*2,shape[3]/2]\n",
    "        \n",
    "        layer=tf.nn.conv2d_transpose(value=input,filter=weights,output_shape=out_shape,strides=stride,padding=\"VALID\")\n",
    "        \n",
    "        return layer\n",
    "    \n",
    "    def copy_and_crop(self,):\n",
    "        pass\n",
    "    def weight(self,shape,name):\n",
    "        return tf.Variable(tf.truncated_normal(shape,stddev=0.05),name=\"weights_\"+name)\n",
    "\n",
    "    def bias(self,shape,name):\n",
    "        return tf.Variable(tf.constant(0.05,shape=[shape]),name=\"bias_\"+name)\n",
    "    def crop_and_concat(self,x1,x2):\n",
    "        x1_shape = tf.shape(x1)\n",
    "        x2_shape = tf.shape(x2)\n",
    "        # offsets for the top left corner of the crop\n",
    "        offsets = [0, (x1_shape[1] - x2_shape[1]) // 2, (x1_shape[2] - x2_shape[2]) // 2, 0]\n",
    "        size = [-1, x2_shape[1], x2_shape[2], -1]\n",
    "        x1_crop = tf.slice(x1, offsets, size)\n",
    "        return tf.concat([x1_crop, x2], 3)   \n",
    "\n",
    "    \n",
    "a=UNET()\n",
    "x=tf.placeholder(tf.float32,shape=[None,572,572,3],name=\"image\")\n",
    "       \n",
    "a.model(x)\n",
    "\n",
    "\"\"\"with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "\n",
    "    print sess.run(a.up1,feed_dict={x:np.array([1,572,572,3])})\"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'with tf.Session() as sess:\\n    # you need to initialize all variables\\n    tf.initialize_all_variables().run()\\n\\n\\n    print sess.run(a.up1,feed_dict={x:np.array([1,572,572,3])})'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=UNET()\n",
    "x=tf.placeholder(tf.float32,shape=[None,572,572,3],name=\"image\")\n",
    "       \n",
    "a.model(x)\n",
    "\n",
    "\"\"\"with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "\n",
    "    print sess.run(a.up1,feed_dict={x:np.array([1,572,572,3])})\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
